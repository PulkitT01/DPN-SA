(2570, 17)
Numpy Train Statistics:
(2570, 19)
(2570, 1)
############### Propensity Score SAE net Training ###############
.. Training started ..
##### train e2e #########
Training mode: train
----- Training SAE -----
Epoch: 100, loss: 0.028181403783368475
Epoch: 200, loss: 0.02043985838162494
Epoch: 300, loss: 0.019218327207375825
Epoch: 400, loss: 0.01794505883353176
.. Propensity score evaluation started using Sparse AE..
Epoch: 25, loss: 15.245428338646889, correct: 2336/2570, accuracy: 0.9089494163424124
Epoch: 50, loss: 14.322885606437922, correct: 2342/2570, accuracy: 0.911284046692607
########## train layer wise all layer active ############
Training mode: train
----- Training SAE -----
Epoch: 100, loss: 0.084969370453446
Epoch: 200, loss: 0.08697423835595448
Epoch: 300, loss: 0.08094914271323769
Epoch: 400, loss: 0.0808385012694347
----- Training SAE -----
Epoch: 100, loss: 0.09052352441681756
Epoch: 200, loss: 0.08884566525618236
Epoch: 300, loss: 0.08618543890339357
Epoch: 400, loss: 0.08574599653114508
.. Propensity score evaluation started using Sparse AE..
Epoch: 25, loss: 15.876364905387163, correct: 2335/2570, accuracy: 0.9085603112840467
Epoch: 50, loss: 15.117095850408077, correct: 2340/2570, accuracy: 0.9105058365758755
########## train layer wise only newly stacked layer active ############
Training mode: train
----- Training SAE -----
Epoch: 100, loss: 0.08507704711806627
Epoch: 200, loss: 0.08233007103388693
Epoch: 300, loss: 0.08124060997808422
Epoch: 400, loss: 0.0773097565052686
----- Training SAE -----
Epoch: 100, loss: 0.08891909771863325
Epoch: 200, loss: 0.09289259518738147
Epoch: 300, loss: 0.08837719247848899
Epoch: 400, loss: 0.08528976554028046
.. Propensity score evaluation started using Sparse AE..
Epoch: 25, loss: 15.85417340695858, correct: 2332/2570, accuracy: 0.9073929961089494
Epoch: 50, loss: 14.810800392180681, correct: 2335/2570, accuracy: 0.9085603112840467
Training completed..
.. Propensity score evaluation started using Sparse AE ..
.. Propensity score evaluation completed Sparse AE ..
treated: 237
control: 2333
total: 2570
[0.052450425922870636, 0.018190253525972366, 0.007932296022772789, 0.023382991552352905, 0.6268736720085144, 0.03710898384451866, 0.06592734158039093, 0.01801726594567299, 0.21088217198848724, 0.09923069924116135, 0.821243941783905, 0.8905192017555237, 0.07750120759010315, 0.015124108642339706, 0.030958322808146477, 0.12554500997066498, 0.2506101131439209, 0.5656386613845825, 0.8260528445243835, 0.3805433213710785, 0.6206523180007935, 0.3497046232223511, 0.8419916033744812, 0.19939620792865753, 0.31156542897224426, 0.13628388941287994, 0.9560850262641907, 0.3229781687259674, 0.38004574179649353, 0.11121881008148193, 0.34847697615623474, 0.35172519087791443, 0.23606815934181213, 0.2567475438117981, 0.37486717104911804, 0.12140759825706482, 0.3766208589076996, 0.38553935289382935, 0.19567759335041046, 0.10415030270814896, 0.29268160462379456, 0.9430361986160278, 0.38100481033325195, 0.3700820803642273, 0.16191720962524414, 0.6228665113449097, 0.3571360111236572, 0.2936550974845886, 0.2737887501716614, 0.19837257266044617, 0.2590641379356384, 0.9263581037521362, 0.11719737201929092, 0.9299766421318054, 0.23423898220062256, 0.015749480575323105, 0.6026716232299805, 0.704002857208252, 0.21087931096553802, 0.3600596487522125, 0.639465868473053, 0.27235737442970276, 0.26774007081985474, 0.3015765845775604, 0.24937377870082855, 0.3449782133102417, 0.1347333937883377, 0.25189322233200073, 0.26743796467781067, 0.24939514696598053, 0.2594221234321594, 0.2542590796947479, 0.23110458254814148, 0.24509352445602417, 0.3831518292427063, 0.24951212108135223, 0.35091063380241394, 0.25043022632598877, 0.2525269091129303, 0.24442660808563232, 0.25190672278404236, 0.24945273995399475, 0.2493387907743454, 0.24905957281589508, 0.3794354796409607, 0.23292413353919983, 0.249036505818367, 0.249036505818367, 0.24234206974506378, 0.24958078563213348, 0.2499677687883377, 0.25169652700424194, 0.17819465696811676, 0.21106283366680145, 0.24936546385288239, 0.24313242733478546, 0.3822004795074463, 0.3927544951438904, 0.24925199151039124, 0.6899148225784302, 0.23800064623355865, 0.25097376108169556, 0.25112026929855347, 0.2900339961051941, 0.26570045948028564, 0.24553728103637695, 0.39416244626045227, 0.23029081523418427, 0.28917327523231506, 0.406861811876297, 0.6569007039070129, 0.24354104697704315, 0.3449782133102417, 0.3568776547908783, 0.8754849433898926, 0.20850808918476105, 0.36035430431365967, 0.20192478597164154, 0.13338874280452728, 0.48343831300735474, 0.3858811855316162, 0.8676961660385132, 0.3798847496509552, 0.3927544951438904, 0.3927544951438904, 0.43518897891044617, 0.11338261514902115, 0.7985081076622009, 0.3823399543762207, 0.23389632999897003, 0.3903980851173401, 0.3903980851173401, 0.37754034996032715, 0.3857382535934448, 0.3892970681190491, 0.37350699305534363, 0.38823097944259644, 0.38823097944259644, 0.38181543350219727, 0.37700653076171875, 0.18990476429462433, 0.6082949638366699, 0.18295376002788544, 0.30977731943130493, 0.2619890570640564, 0.25966623425483704, 0.2742781937122345, 0.2655072510242462, 0.9251191020011902, 0.24864976108074188, 0.2455255538225174, 0.2558939754962921, 0.26450616121292114, 0.04662429168820381, 0.24980980157852173, 0.27526214718818665, 0.8271117806434631, 0.2542590796947479, 0.24916581809520721, 0.25046756863594055, 0.2505556643009186, 0.24936099350452423, 0.2506273686885834, 0.24473313987255096, 0.2490009069442749, 0.2542590796947479, 0.2498701959848404, 0.26180335879325867, 0.25966623425483704, 0.25966623425483704, 0.25382936000823975, 0.26141414046287537, 0.2559494972229004, 0.25663313269615173, 0.8058066368103027, 0.2525262236595154, 0.25288403034210205, 0.2499304860830307, 0.29616865515708923, 0.25621429085731506, 0.2526495158672333, 0.2526495158672333, 0.24442051351070404, 0.25165048241615295, 0.2535756230354309, 0.2494642436504364, 0.25361067056655884, 0.2538944184780121, 0.25043022632598877, 0.24916581809520721, 0.24916581809520721, 0.24984151124954224, 0.2498907446861267, 0.25106358528137207, 0.25277435779571533, 0.2540074288845062, 0.25445348024368286, 0.24945637583732605, 0.25243982672691345, 0.25007084012031555, 0.24949795007705688, 0.24965894222259521, 0.25597327947616577, 0.24919156730175018, 0.24979166686534882, 0.24930453300476074, 0.24935083091259003, 0.24758677184581757, 0.24992883205413818, 0.24999772012233734, 0.24980822205543518, 0.250622034072876, 0.24921315908432007, 0.24935884773731232, 0.24931247532367706, 0.2498895823955536, 0.24938850104808807, 0.2493813931941986, 0.249036505818367, 0.24947525560855865, 0.24903026223182678, 0.24931368231773376, 0.24874062836170197, 0.24953369796276093, 0.24965764582157135, 0.24928508698940277, 0.2498609870672226, 0.2585117816925049, 0.2585117816925049, 0.5777507424354553, 0.2507288157939911, 0.24868904054164886, 0.24813289940357208, 0.24822142720222473, 0.18755696713924408, 0.247395858168602, 0.2480589747428894]
Using original data
cuda:0
{'epochs': 400, 'lr': 0.001, 'batch_size': 32, 'shuffle': True, 'sparsity_probability': 0.8, 'weight_decay': 0.0003, 'BETA': 0.1}
########### 400 epochs ###########
----------------------------------------
iter_id: 0
----------------------------------------
(2570, 17)
Numpy Train Statistics:
(2570, 19)
(2570, 1)
 Numpy Test Statistics:
(642, 19)
(642, 1)
----------- Training and evaluation phase ------------
############### Propensity Score neural net Training ###############
.. Training started ..
Saved model path: ./Propensity_Model/NN_PS_model_iter_id_0_epoch_50_lr_0.001.pth
Epoch: 25, loss: 15.255986500531435, correct: 2336/2570, accuracy: 0.9089494163424124
Epoch: 50, loss: 14.538009982556105, correct: 2343/2570, accuracy: 0.9116731517509727
Saved model..
.. Propensity score evaluation started using NN..
.. Propensity score evaluation completed using NN..
############### DCN Training using NN ###############
 Treated Statistics ==>
(237, 17)
 Control Statistics ==>
(2333, 17)
Saved model path: ./DCNModel/NN_DCN_model_iter_id_0_epoch_100_lr_0.0001.pth
.. Training started ..
cuda:0
epoch: 9, Treated + Control loss: 865.3322868636752
epoch: 19, Treated + Control loss: 825.9371034798944
epoch: 29, Treated + Control loss: 798.7245214072245
epoch: 39, Treated + Control loss: 789.3966878662219
epoch: 49, Treated + Control loss: 784.4646159681688
epoch: 59, Treated + Control loss: 777.0438956814241
epoch: 69, Treated + Control loss: 766.324315026671
epoch: 79, Treated + Control loss: 753.30528798095
epoch: 89, Treated + Control loss: 745.0734926342075
epoch: 99, Treated + Control loss: 728.4635726294397
Neural Net start time: = 2024-12-19 20:27:00.927338
Neural Net end time: = 2024-12-19 20:36:46.696548
{'epochs': 400, 'lr': 0.001, 'batch_size': 32, 'shuffle': True, 'train_set': <torch.utils.data.dataset.TensorDataset object at 0x14d5c012ec80>, 'sparsity_probability': 0.8, 'weight_decay': 0.0003, 'BETA': 0.1, 'input_nodes': 17}
############### Propensity Score SAE net Training ###############
.. Training started ..
##### train e2e #########
Training mode: train
----- Training SAE -----
Epoch: 100, loss: 0.035785177124687186
Epoch: 200, loss: 0.021215547865003716
Epoch: 300, loss: 0.01900802999389944
Epoch: 400, loss: 0.01842974482771055
.. Propensity score evaluation started using Sparse AE..
Epoch: 25, loss: 15.41915987804532, correct: 2322/2570, accuracy: 0.9035019455252918
Epoch: 50, loss: 14.278081201016903, correct: 2349/2570, accuracy: 0.9140077821011673
########## train layer wise all layer active ############
Training mode: train
----- Training SAE -----
Epoch: 100, loss: 0.08957580467801035
Epoch: 200, loss: 0.08419344725984114
Epoch: 300, loss: 0.09624463853276806
Epoch: 400, loss: 0.08470287183184683
----- Training SAE -----
Epoch: 100, loss: 0.09021775447476058
Epoch: 200, loss: 0.09097953122339131
Epoch: 300, loss: 0.09057063793326602
Epoch: 400, loss: 0.08555818661863421
.. Propensity score evaluation started using Sparse AE..
Epoch: 25, loss: 15.914905726909637, correct: 2333/2570, accuracy: 0.9077821011673152
Epoch: 50, loss: 14.735185220837593, correct: 2343/2570, accuracy: 0.9116731517509727
########## train layer wise only newly stacked layer active ############
Training mode: train
----- Training SAE -----
Epoch: 100, loss: 0.08364858367928753
Epoch: 200, loss: 0.08350421538875427
Epoch: 300, loss: 0.08125573725520092
Epoch: 400, loss: 0.08343816107070004
----- Training SAE -----
Epoch: 100, loss: 0.08929947588914706
Epoch: 200, loss: 0.08984028814751426
Epoch: 300, loss: 0.08813350242965015
Epoch: 400, loss: 0.08984616095269168
.. Propensity score evaluation started using Sparse AE..
Epoch: 25, loss: 16.530512303113937, correct: 2308/2570, accuracy: 0.8980544747081712
Epoch: 50, loss: 15.324317593127489, correct: 2327/2570, accuracy: 0.9054474708171206
Training completed..
---------------------------------------------------------------------------
End to End SAE training
---------------------------------------------------------------------------
.. Propensity score evaluation started using Sparse AE ..
.. Propensity score evaluation completed Sparse AE ..
############### DCN Training using SAE ###############
 Treated Statistics ==>
(237, 17)
 Control Statistics ==>
(2333, 17)
Saved model path: ./DCNModel/SAE_E2E_DCN_model_iter_id_0_epoch_100_lr_0.0001.pth
.. Training started ..
cuda:0
epoch: 9, Treated + Control loss: 872.9933062331107
epoch: 19, Treated + Control loss: 822.8913353724547
epoch: 29, Treated + Control loss: 793.2562848977578
epoch: 39, Treated + Control loss: 804.3385479931418
epoch: 49, Treated + Control loss: 784.6155616989288
epoch: 59, Treated + Control loss: 755.7393141465561
epoch: 69, Treated + Control loss: 748.4372789106202
epoch: 79, Treated + Control loss: 763.1318304838034
epoch: 89, Treated + Control loss: 725.0598203425504
epoch: 99, Treated + Control loss: 743.9723420586888
SAE E2E start time: = 2024-12-19 21:12:16.341702
SAE E2E end time: = 2024-12-19 21:21:15.736836
---------------------------------------------------------------------------
----------Layer wise greedy stacked SAE training - All layers----------
---------------------------------------------------------------------------
.. Propensity score evaluation started using Sparse AE ..
.. Propensity score evaluation completed Sparse AE ..
############### DCN Training using SAE ###############
 Treated Statistics ==>
(237, 17)
 Control Statistics ==>
(2333, 17)
Saved model path: ./DCNModel/SAE_stacked_all_DCN_model_iter_id_0_epoch_100_lr_0.0001.pth
.. Training started ..
cuda:0
epoch: 9, Treated + Control loss: 842.1199133404466
epoch: 19, Treated + Control loss: 825.2317401339382
epoch: 29, Treated + Control loss: 791.0824096565409
epoch: 39, Treated + Control loss: 787.1465813946985
epoch: 49, Treated + Control loss: 772.781276516571
epoch: 59, Treated + Control loss: 754.4077315881594
epoch: 69, Treated + Control loss: 756.5788236092875
epoch: 79, Treated + Control loss: 723.8929234184204
epoch: 89, Treated + Control loss: 738.96816474095
epoch: 99, Treated + Control loss: 754.5324043084377
SAE all layer active start time: = 2024-12-19 21:21:15.736857
SAE all layer active end time: = 2024-12-19 21:30:14.701225
---------------------------------------------------------------------------
Layer wise greedy stacked SAE training - Current layers
---------------------------------------------------------------------------
.. Propensity score evaluation started using Sparse AE ..
.. Propensity score evaluation completed Sparse AE ..
############### DCN Training using SAE ###############
 Treated Statistics ==>
(237, 17)
 Control Statistics ==>
(2333, 17)
Saved model path: ./DCNModel/SAE_stacked_cur_DCN_model_iter_id_0_epoch_100_lr_0.0001.pth
.. Training started ..
cuda:0
epoch: 9, Treated + Control loss: 843.6400885037701
epoch: 19, Treated + Control loss: 795.4338502025298
epoch: 29, Treated + Control loss: 797.2592901358983
epoch: 39, Treated + Control loss: 784.5416246749916
epoch: 49, Treated + Control loss: 773.194462446676
epoch: 59, Treated + Control loss: 767.7523105646362
epoch: 69, Treated + Control loss: 753.4905937913809
epoch: 79, Treated + Control loss: 747.7844775715929
epoch: 89, Treated + Control loss: 733.1687363932238
epoch: 99, Treated + Control loss: 730.6782400551276
SAE cur layer active start time: = 2024-12-19 21:30:14.701247
SAE all layer active end time: = 2024-12-19 21:39:13.373153
############### DCN Training using Logistic Regression ###############
 Treated Statistics ==>
(237, 17)
 Control Statistics ==>
(2333, 17)
Saved model path: ./DCNModel/LR_DCN_model_iter_id_0_epoch_100_lr_0.0001.pth
.. Training started ..
cuda:0
epoch: 9, Treated + Control loss: 871.2207763910042
epoch: 19, Treated + Control loss: 819.7306053793175
epoch: 29, Treated + Control loss: 798.3854650412126
epoch: 39, Treated + Control loss: 784.4009059730131
epoch: 49, Treated + Control loss: 767.3532877254343
epoch: 59, Treated + Control loss: 763.8940319874341
epoch: 69, Treated + Control loss: 757.3731843141662
epoch: 79, Treated + Control loss: 742.0100670996301
epoch: 89, Treated + Control loss: 749.0904582360209
epoch: 99, Treated + Control loss: 761.3235763885621
Logistic Regression start time: = 2024-12-19 21:39:13.373180
Logistic Regression end time: = 2024-12-19 21:48:06.893331
############### DCN Training using Logistic Regression Lasso ###############
 Treated Statistics ==>
(237, 17)
 Control Statistics ==>
(2333, 17)
Saved model path: ./DCNModel/LR_Lasso_DCN_model_iter_id_0_epoch_100_lr_0.0001.pth
.. Training started ..
cuda:0
epoch: 9, Treated + Control loss: 876.2000889256965
epoch: 19, Treated + Control loss: 830.6639218950088
epoch: 29, Treated + Control loss: 794.8306811782954
epoch: 39, Treated + Control loss: 803.1100789693791
epoch: 49, Treated + Control loss: 768.4337488168563
epoch: 59, Treated + Control loss: 757.0398578860634
epoch: 69, Treated + Control loss: 769.2716746349603
epoch: 79, Treated + Control loss: 762.6113282034504
epoch: 89, Treated + Control loss: 753.123774061534
epoch: 99, Treated + Control loss: 734.1051318361583
Logistic Regression Lasso start time: = 2024-12-19 21:48:06.893373
Logistic Regression Lasso end time: = 2024-12-19 21:57:01.089617
----------- Testing phase ------------
############### DCN Testing using NN ###############
.. Propensity score evaluation started using NN..
.. Propensity score evaluation completed using NN..
 Treated Statistics ==>
(60, 17)
 Control Statistics ==>
(582, 17)
.. Evaluation started ..
